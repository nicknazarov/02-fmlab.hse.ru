stuff <- list(scores =scores , batchs=batchs, batch_elements=batch_elements)  # список ценных объектов
saveRDS(file = "assessors_v1.RDS",stuff) # сохраняем всё ценное в файл
mylist <- readRDS("assessors_v1.RDS.RDS") # читаем из файла что там есть
mylist <- readRDS("assessors_v1.RDS") # читаем из файла что там есть
dat<-mylist [[1]]
View(dat)
library(RPostgreSQL)
library(DT)
library(RPostgreSQL)
getDataFromDB <- function(query) {
# Функция получения данных по sql запросу
# Args:
#   query: sql запрос
# Returns:
#   ДатаФрейм с результатами запроса
database="assessment"
conection <- dbConnect(PostgreSQL(), user= "analyst", password="analyst_ltr",
dbname=database, host="searchqa-db.search.km")
sqlResults <- dbSendQuery(conection, query)
data <- fetch(sqlResults, n=-1)
dbClearResult(sqlResults)
dbDisconnect(conection)
return(data)
}
scores <- getDataFromDB("
SELECT  * FROM scores
")
stuff <- list(scores =scores)  # список ценных объектов
saveRDS(file = "assessors_v2.RDS",stuff) # сохраняем всё ценное в файл
mylist <- readRDS("assessors_v2.RDS") # читаем из файла что там есть
data.scores<-mylist [[1]]
assessor.id <- getDataFromDB("
SELECT DISTINCT assess_id FROM scores
")
View(assessor.id)
View(assessor.id)
assessor.id <- getDataFromDB("
SELECT DISTINCT assess_id FROM scores SORT BY assess_id
")
assessor.id <- getDataFromDB("
SELECT DISTINCT assess_id FROM scores SORTED BY assess_id
")
assessor.id <- getDataFromDB("
SELECT DISTINCT assess_id FROM scores ORDER BY assess_id
")
View(assessor.id)
require(stats)
by(warpbreaks[, 1:2], warpbreaks[,"tension"], summary)
warpbreaks
View(scores)
View(scores)
coherence.table <- data.frame(1,1,1,1)
colnames(coherence.table) <- c("First_assessor","Second_assessor","N","Coeff_of_coherence")
for (i in 1:(nrow(assessor.id)-1) ){
left.table <- scores [assess_id==assessor.id[i]]
for (k in (i+1):nrow(assessor.id) ){
right.table <- scores [assess_id==assessor.id[k]]
result.merge.table <- merge(x = left.table[,c(2,8,9)], y = right.table[,c(2,8,9)], by = "batch_element_id", all = TRUE)
common.marks <- result.merge.table[,3]-result.merge.table[,6]
coher <- length(common.marks[common.marks==0])
coherence.table <- list(assessor.id[i], assessor.id[k], nrow(result.merge.table), coher/ nrow(result.merge.table)*100)
}
}
coherence.table <- data.frame(1,1,1,1)
colnames(coherence.table) <- c("First_assessor","Second_assessor","N","Coeff_of_coherence")
for (i in 1:(nrow(assessor.id)-1) ){
left.table <- scores [left.table$assess_id==assessor.id[i]]
for (k in (i+1):nrow(assessor.id) ){
right.table <- scores [right.table$assess_id==assessor.id[k]]
result.merge.table <- merge(x = left.table[,c(2,8,9)], y = right.table[,c(2,8,9)], by = "batch_element_id", all = TRUE)
common.marks <- result.merge.table[,3]-result.merge.table[,6]
coher <- length(common.marks[common.marks==0])
coherence.table <- list(assessor.id[i], assessor.id[k], nrow(result.merge.table), coher/ nrow(result.merge.table)*100)
}
}
#data.scores<-mylist [[1]]
coherence.table <- data.frame(1,1,1,1)
colnames(coherence.table) <- c("First_assessor","Second_assessor","N","Coeff_of_coherence")
for (i in 1:(nrow(assessor.id)-1) ){
left.table <- scores [scores$assess_id==assessor.id[i]]
for (k in (i+1):nrow(assessor.id) ){
right.table <- scores [scores$assess_id==assessor.id[k]]
result.merge.table <- merge(x = left.table[,c(2,8,9)], y = right.table[,c(2,8,9)], by = "batch_element_id", all = TRUE)
common.marks <- result.merge.table[,3]-result.merge.table[,6]
coher <- length(common.marks[common.marks==0])
coherence.table <- list(assessor.id[i], assessor.id[k], nrow(result.merge.table), coher/ nrow(result.merge.table)*100)
}
}
#data.scores<-mylist [[1]]
coherence.table <- data.frame(1,1,1,1)
colnames(coherence.table) <- c("First_assessor","Second_assessor","N","Coeff_of_coherence")
for (i in 1:(nrow(assessor.id)-1) ){
left.table <- scores [scores$assess_id==assessor.id[i]]
for (k in (i+1):nrow(assessor.id) ){
right.table <- scores [scores$assess_id==assessor.id[k]]
result.merge.table <- merge(x = left.table[,c(2,8,9)], y = right.table[,c(2,8,9)], by = "batch_element_id", all = TRUE)
common.marks <- result.merge.table[,3]-result.merge.table[,6]
coher <- length(common.marks[common.marks==0])
coherence.table <- list(assessor.id[i], assessor.id[k], nrow(result.merge.table), coher/ nrow(result.merge.table)*100)
}
print(i)
}
#data.scores<-mylist [[1]]
coherence.table <- data.frame(1,1,1,1)
colnames(coherence.table) <- c("First_assessor","Second_assessor","N","Coeff_of_coherence")
for (i in 1:(nrow(assessor.id)-1) ){
left.table <- scores [scores$assess_id==assessor.id[i]]
for (k in (i+1):nrow(assessor.id) ){
print(k)
right.table <- scores [scores$assess_id==assessor.id[k]]
result.merge.table <- merge(x = left.table[,c(2,8,9)], y = right.table[,c(2,8,9)], by = "batch_element_id", all = TRUE)
common.marks <- result.merge.table[,3]-result.merge.table[,6]
coher <- length(common.marks[common.marks==0])
coherence.table <- list(assessor.id[i], assessor.id[k], nrow(result.merge.table), coher/ nrow(result.merge.table)*100)
}
}
#saveRDS(file = "assessors_v2.RDS",stuff) # сохраняем всё ценное в файл
#mylist <- readRDS("assessors_v2.RDS") # читаем из файла что там есть
#data.scores<-mylist [[1]]
coherence.table <- data.frame(1,1,1,1)
colnames(coherence.table) <- c("First_assessor","Second_assessor","N","Coeff_of_coherence")
for (i in 1:(nrow(assessor.id)-1) ){
left.table <- scores [scores$assess_id==assessor.id[i]]
for (k in (i+1):nrow(assessor.id) ){
print(k)
right.table <- scores [scores$assess_id==assessor.id[k]]
if (nrow( right.table )!=0){
result.merge.table <- merge(x = left.table[,c(2,8,9)], y = right.table[,c(2,8,9)], by = "batch_element_id", all = TRUE)
common.marks <- result.merge.table[,3]-result.merge.table[,6]
coher <- length(common.marks[common.marks==0])
coherence.table <- list(assessor.id[i], assessor.id[k], nrow(result.merge.table), coher/ nrow(result.merge.table)*100)
}
else{
coherence.table <- list(assessor.id[i], assessor.id[k], 0, 0)
}
}
}
coherence.table <- data.frame(1,1,1,1)
colnames(coherence.table) <- c("First_assessor","Second_assessor","N","Coeff_of_coherence")
for (i in 1:(nrow(assessor.id)-1) ){
left.table <- scores [scores$assess_id==assessor.id[i]]
for (k in (i+1):nrow(assessor.id) ){
print(k)
flush.console()
right.table <- scores [scores$assess_id==assessor.id[k]]
if (nrow( right.table )!=0){
result.merge.table <- merge(x = left.table[,c(2,8,9)], y = right.table[,c(2,8,9)], by = "batch_element_id", all = TRUE)
common.marks <- result.merge.table[,3]-result.merge.table[,6]
coher <- length(common.marks[common.marks==0])
coherence.table <- list(assessor.id[i], assessor.id[k], nrow(result.merge.table), coher/ nrow(result.merge.table)*100)
}
else{
coherence.table <- list(assessor.id[i], assessor.id[k], 0, 0)
}
}
}
View(assessor.id)
#data.scores<-mylist [[1]]
coherence.table <- data.frame(1,1,1,1)
colnames(coherence.table) <- c("First_assessor","Second_assessor","N","Coeff_of_coherence")
for (i in 1:(nrow(assessor.id)-1) ){
left.table <- scores [scores$assess_id==assessor.id[i,1]]
for (k in (i+1):nrow(assessor.id) ){
print(k)
flush.console()
right.table <- scores [scores$assess_id==assessor.id[k,1]]
if (nrow( right.table )!=0){
result.merge.table <- merge(x = left.table[,c(2,8,9)], y = right.table[,c(2,8,9)], by = "batch_element_id", all = TRUE)
common.marks <- result.merge.table[,3]-result.merge.table[,6]
coher <- length(common.marks[common.marks==0])
coherence.table <- list(assessor.id[i], assessor.id[k], nrow(result.merge.table), coher/ nrow(result.merge.table)*100)
}
else{
coherence.table <- list(assessor.id[i], assessor.id[k], 0, 0)
}
}
}
assessor.id[1,1]
assessor.id[2,1]
scores$assess_id
scores [scores$assess_id==assessor.id[1,1]]
#! /usr/bin/R --no-restore --no-save -f
#############################################################################
# Загрузка
#setwd("/home/nazarov/task_5/RankingAnalysis")
source("R/Boot.R")
libraryBoot()
sourceBoot()
#############################################################################
# Константы
# Путь к learn обучения
#LEARN_PATH <- "~/WebExperimentClean/data_set_test.txt"
#LEARN_PATH <- "/home/nazarov/task_5/29_old/PP_our_asess_old+new.txt"
LEARN_PATH <- "/home/nazarov/task_7/mihailov/data_set_all_processsed.txt"
#############################################################################
# Фиксация рандома
set.seed(481516)
#############################################################################
# Чтение данных
print(sprintf("%s Start", Sys.time()))
data <- readDataset(LEARN_PATH)
rankingData <- data$features
metaData <- data$meta
relevanceDiscr <- cut(x=rankingData$RelevanceScore, breaks=c(0, 0.5, 1.5, 2.5, 3.5, 4.0), include.lowest=TRUE)
rankingData <- cbind(rankingData, RelevanceDiscr=relevanceDiscr)
#############################################################################
# Подсчет необходимых статистик
uniqueNumberInFeature <- apply(rankingData, MARGIN=2, FUN=function(column) return(length(unique(column))))
unaryFeatureIndex <- which(uniqueNumberInFeature == 1)
binaryFeatureIndex <- which(uniqueNumberInFeature == 2)
discreteFeatureIndex <- which(uniqueNumberInFeature > 2 & uniqueNumberInFeature <= 15)
continuosFeatureIndex <- setdiff(3:ncol(rankingData), which(uniqueNumberInFeature <= 15))
# dataToBind <- cbind(metaData[, c(1, 3)], RelevanceScore=rankingData$RelevanceScore)
# queryGroop <- split(x=dataToBind, f=rankingData$QueryId)
#
# relQueryQuality <- sapply(queryGroop, FUN=function(data) { x <- sum(data$RelevanceScore >= 1.5); return(x)})
# queriesFirst <- sapply(queryGroop[relQueryQuality == 0], FUN=function(data) { return(data[1, 1])})
#
# relQueryQuality <- sapply(queryGroop, FUN=function(data) { x <- sum(data$RelevanceScore >= 2.0); return(x)})
# queriesSecond <- sapply(queryGroop[relQueryQuality == 0], FUN=function(data) { return(data[1, 1])})
# queriesSecond <- setdiff(queriesSecond, queriesFirst)
#
# relQueryQuality <- sapply(queryGroop, FUN=function(data) { x <- sum(data$RelevanceScore >= 2.5); return(x)})
# queriesThird <- sapply(queryGroop[relQueryQuality == 0], FUN=function(data) { return(data[1, 1])})
# queriesThird <- setdiff(queriesThird, union(queriesFirst, queriesSecond))
#############################################################################
# Генерация html кода и рассылка на почту
knit(input="R/ExpAnalysis.rmd", output="ExpAnalysis.md", encoding='UTF-8')
markdownToHTML("ExpAnalysis.md", "results/ExpAnalysis.html", stylesheet="data/custom.css")
file.remove("ExpAnalysis.md")
# paramsList <- list()
# paramsList$fromAddress <- c("-f 'sputnikanal@gmail.com'")
# paramsList$toAddress <- c("-t 'sputnikanal@gmail.com'")
# paramsList$emailSubject <- c("-u DataSet predAnalys Results")
# #paramsList$listemailMessage <- c("-m ")
# paramsList$serverAndPort <- c("-s 'smtp.gmail.com:25'")
# paramsList$fileAttachPath <- c("-a results/ExpAnalys.html")
# paramsList$accUsername <- c("-xu sputnikanal@gmail.com")
# paramsList$accPassword <- c("-xp sputnik1234")
#
# command <- paste(paramsList, collapse = " ")
# command <- paste("sendEmail", command,sep = " ")
# system(command, intern=T, wait=T)
#############################################################################
# Вывод плохих запросов
#write.table(row.names=FALSE, col.names=FALSE, file="results/quiriesBadFirst.txt", queriesFirst, quote=FALSE)
#write.table(row.names=FALSE, col.names=FALSE, file="results/quiriesBadSecond.txt", queriesSecond, quote=FALSE)
#write.table(row.names=FALSE, col.names=FALSE, file="results/quiriesBadThird.txt", queriesThird, quote=FALSE)
#! /usr/bin/R --no-restore --no-save -f
#############################################################################
# Загрузка
setwd("/home/nazarov/task_7/RankingAnalysis")
source("R/Boot.R")
libraryBoot()
sourceBoot()
#############################################################################
# Константы
# Путь к learn обучения
#LEARN_PATH <- "~/WebExperimentClean/data_set_test.txt"
#LEARN_PATH <- "/home/nazarov/task_5/29_old/PP_our_asess_old+new.txt"
LEARN_PATH <- "/home/nazarov/task_7/mihailov/data_set_all_processsed.txt"
#############################################################################
# Фиксация рандома
set.seed(481516)
#############################################################################
# Чтение данных
print(sprintf("%s Start", Sys.time()))
data <- readDataset(LEARN_PATH)
rankingData <- data$features
metaData <- data$meta
relevanceDiscr <- cut(x=rankingData$RelevanceScore, breaks=c(0, 0.5, 1.5, 2.5, 3.5, 4.0), include.lowest=TRUE)
rankingData <- cbind(rankingData, RelevanceDiscr=relevanceDiscr)
#############################################################################
# Подсчет необходимых статистик
uniqueNumberInFeature <- apply(rankingData, MARGIN=2, FUN=function(column) return(length(unique(column))))
unaryFeatureIndex <- which(uniqueNumberInFeature == 1)
binaryFeatureIndex <- which(uniqueNumberInFeature == 2)
discreteFeatureIndex <- which(uniqueNumberInFeature > 2 & uniqueNumberInFeature <= 15)
continuosFeatureIndex <- setdiff(3:ncol(rankingData), which(uniqueNumberInFeature <= 15))
# dataToBind <- cbind(metaData[, c(1, 3)], RelevanceScore=rankingData$RelevanceScore)
# queryGroop <- split(x=dataToBind, f=rankingData$QueryId)
#
# relQueryQuality <- sapply(queryGroop, FUN=function(data) { x <- sum(data$RelevanceScore >= 1.5); return(x)})
# queriesFirst <- sapply(queryGroop[relQueryQuality == 0], FUN=function(data) { return(data[1, 1])})
#
# relQueryQuality <- sapply(queryGroop, FUN=function(data) { x <- sum(data$RelevanceScore >= 2.0); return(x)})
# queriesSecond <- sapply(queryGroop[relQueryQuality == 0], FUN=function(data) { return(data[1, 1])})
# queriesSecond <- setdiff(queriesSecond, queriesFirst)
#
# relQueryQuality <- sapply(queryGroop, FUN=function(data) { x <- sum(data$RelevanceScore >= 2.5); return(x)})
# queriesThird <- sapply(queryGroop[relQueryQuality == 0], FUN=function(data) { return(data[1, 1])})
# queriesThird <- setdiff(queriesThird, union(queriesFirst, queriesSecond))
#############################################################################
# Генерация html кода и рассылка на почту
knit(input="R/ExpAnalysis.rmd", output="ExpAnalysis.md", encoding='UTF-8')
markdownToHTML("ExpAnalysis.md", "results/ExpAnalysis.html", stylesheet="data/custom.css")
file.remove("ExpAnalysis.md")
# paramsList <- list()
# paramsList$fromAddress <- c("-f 'sputnikanal@gmail.com'")
# paramsList$toAddress <- c("-t 'sputnikanal@gmail.com'")
# paramsList$emailSubject <- c("-u DataSet predAnalys Results")
# #paramsList$listemailMessage <- c("-m ")
# paramsList$serverAndPort <- c("-s 'smtp.gmail.com:25'")
# paramsList$fileAttachPath <- c("-a results/ExpAnalys.html")
# paramsList$accUsername <- c("-xu sputnikanal@gmail.com")
# paramsList$accPassword <- c("-xp sputnik1234")
#
# command <- paste(paramsList, collapse = " ")
# command <- paste("sendEmail", command,sep = " ")
# system(command, intern=T, wait=T)
#############################################################################
# Вывод плохих запросов
#write.table(row.names=FALSE, col.names=FALSE, file="results/quiriesBadFirst.txt", queriesFirst, quote=FALSE)
#write.table(row.names=FALSE, col.names=FALSE, file="results/quiriesBadSecond.txt", queriesSecond, quote=FALSE)
#write.table(row.names=FALSE, col.names=FALSE, file="results/quiriesBadThird.txt", queriesThird, quote=FALSE)
#! /usr/bin/R --no-restore --no-save -f
#############################################################################
# Загрузка
setwd("/home/nazarov/task_7/RankingAnalysis")
source("R/Boot.R")
libraryBoot()
sourceBoot()
setwd("/home/nazarov/task_7/RankingAnalysis")
# Производим тестирование на влияние дня недели, выбираемого для формирования недельных цен закрытия, на перфоманс стратегий
#
# Всего пять файлов, в каждом соответствующие дневные цены закрытия. Из них пересчитываются недельные цены закрытия.
# Далее для каждого файла с недельными ценами закрытия  проводится процедура формирования портфелей и выбора лучшей стратегии.
# Собираем все результаты в один отчет
#
rm(list=ls())
library(XLConnect)
library(pander)
library(DT)
panderOptions('table.split.table', Inf)
library(ggplot2)
library(scales)
source("R/reality_func2.R")
#############################################################################
# Параметры, которые зависят от изучаемой страны
country_name <- "Индия"
country_name_eng <- "India"
#
#temp <- ret(4, 1, 4, STEP, N, price_d1, UP1, UP2, 0.3)
#T <- 164
T <- 456
#############################################################################
# Загрузка
setwd("/home/nazarov/02-fmlab.hse.ru/02 - независимость от дня недели/")
price_d1<- readWorksheet(loadWorkbook(paste(country_name,"/Monday_price.xlsx",sep="")),sheet=1)
price_d2<- readWorksheet(loadWorkbook(paste(country_name,"/Tuesday_price.xlsx",sep="")),sheet=1)
price_d3<- readWorksheet(loadWorkbook(paste(country_name,"/Wednesday_price.xlsx",sep="")),sheet=1)
price_d4<- readWorksheet(loadWorkbook(paste(country_name,"/Thursday_price.xlsx",sep="")),sheet=1)
price_d5<- readWorksheet(loadWorkbook(paste(country_name,"/Friday_price.xlsx",sep="")),sheet=1)
row.names(price_d1) <- price_d1[,1]
price_d1 <-price_d1[,-1]
row.names(price_d2) <- price_d2[,1]
price_d2 <-price_d2[,-1]
row.names(price_d3) <- price_d3[,1]
price_d3 <-price_d3[,-1]
row.names(price_d4) <- price_d4[,1]
price_d4 <-price_d4[,-1]
row.names(price_d5) <- price_d5[,1]
price_d5 <-price_d5[,-1]
price_data <- list (price_d1,price_d2,price_d3,price_d4,price_d5)
#############################################################################
# Константы
# перебор от 1 до 12 мес , ждем от 0 до 8 недель, держим от 1 до 12 мес
# таким образом  последние 25 месяцев понадобятся только для одной модели
# Шаг для подсчета разниц в группах победителей и проигравших
STEP=1
# Периоды отбора (в месяцах), удержания (в неделях), инвестирования (в месяцах)
UP1=12
UP2=8
UP3=12
# N - с учетом отступа
N <- (nrow(price_d1)-(2+UP3*4))%/%STEP
#n <- T-R+1
#############################################################################
# Процедура P&R stationary bootstrap
# Фиксация рандома
set.seed(42)
# Константы для reality check
R <- 1
N_rc <- 500
Q <- 0.1
P_R_ind <- data.frame(P_R(R,T,Q))
for (i in 2:N_rc){
P_R_ind[,i]  <-  P_R(R,T,Q)
}
############################################
setwd("/home/nazarov/02-fmlab.hse.ru/02 - независимость от дня недели/")
rm(list=ls())
library(XLConnect)
library(pander)
library(DT)
panderOptions('table.split.table', Inf)
library(ggplot2)
library(scales)
source("R/reality_func2.R")
#############################################################################
# Параметры, которые зависят от изучаемой страны
country_name <- "Индия"
country_name_eng <- "India"
#
#temp <- ret(4, 1, 4, STEP, N, price_d1, UP1, UP2, 0.3)
#T <- 164
T <- 456
#############################################################################
# Загрузка
price_d1<- readWorksheet(loadWorkbook(paste(country_name,"/Monday_price.xlsx",sep="")),sheet=1)
price_d2<- readWorksheet(loadWorkbook(paste(country_name,"/Tuesday_price.xlsx",sep="")),sheet=1)
price_d3<- readWorksheet(loadWorkbook(paste(country_name,"/Wednesday_price.xlsx",sep="")),sheet=1)
price_d4<- readWorksheet(loadWorkbook(paste(country_name,"/Thursday_price.xlsx",sep="")),sheet=1)
price_d5<- readWorksheet(loadWorkbook(paste(country_name,"/Friday_price.xlsx",sep="")),sheet=1)
row.names(price_d1) <- price_d1[,1]
price_d1 <-price_d1[,-1]
row.names(price_d2) <- price_d2[,1]
price_d2 <-price_d2[,-1]
row.names(price_d3) <- price_d3[,1]
price_d3 <-price_d3[,-1]
row.names(price_d4) <- price_d4[,1]
price_d4 <-price_d4[,-1]
row.names(price_d5) <- price_d5[,1]
price_d5 <-price_d5[,-1]
price_data <- list (price_d1,price_d2,price_d3,price_d4,price_d5)
#############################################################################
# Константы
# перебор от 1 до 12 мес , ждем от 0 до 8 недель, держим от 1 до 12 мес
# таким образом  последние 25 месяцев понадобятся только для одной модели
# Шаг для подсчета разниц в группах победителей и проигравших
STEP=1
# Периоды отбора (в месяцах), удержания (в неделях), инвестирования (в месяцах)
UP1=12
UP2=8
UP3=12
# N - с учетом отступа
N <- (nrow(price_d1)-(2+UP3*4))%/%STEP
#n <- T-R+1
#############################################################################
# Процедура P&R stationary bootstrap
# Фиксация рандома
set.seed(42)
# Константы для reality check
R <- 1
N_rc <- 500
Q <- 0.1
P_R_ind <- data.frame(P_R(R,T,Q))
for (i in 2:N_rc){
P_R_ind[,i]  <-  P_R(R,T,Q)
}
#############################################################################
list_of_restable <-list(readRDS("India_potfolio_day_1.RDS"),readRDS("India_potfolio_day_2.RDS"))  # читаем из файла что там есть
knit(input="R/2html_5days_short.rmd", output="2html_5days_short.md", encoding='UTF-8')
markdownToHTML("2html_5days_short.md","results/Календарные_эффекты.html", stylesheet="view/custom.css")
file.remove("2html_5days_short.md")
#print(sprintf("%s End", Sys.time()))
list_of_restable <-list(readRDS("results/India_potfolio_day_1.RDS"),readRDS("results/India_potfolio_day_2.RDS"))  # читаем из файла что там есть
knit(input="R/2html_5days_short.rmd", output="2html_5days_short.md", encoding='UTF-8')
markdownToHTML("2html_5days_short.md","results/Календарные_эффекты.html", stylesheet="view/custom.css")
file.remove("2html_5days_short.md")
#print(sprintf("%s End", Sys.time()))
knit(input="R/2html_5days_short.rmd", output="2html_5days_short.md", encoding='UTF-8')
library(knitr)
knit(input="R/2html_5days_short.rmd", output="2html_5days_short.md", encoding='UTF-8')
knit(input="2html_5days_short.rmd", output="2html_5days_short.md", encoding='UTF-8')
resultDataFull <- price_d1
knit(input="2html_5days_short.rmd", output="2html_5days_short.md", encoding='UTF-8')
knit(input="2html_5days_short.rmd", output="2html_5days_short.md", encoding='UTF-8')
mylist <- list_of_restable[1]
result.data <- mylist[[1]]
price_data <- list (price_d1,price_d2,price_d3,price_d4,price_d5)
price_data[1]
a<-price_data[1]
a<-price_data[[1]]
mylist <- list_of_restable[[1]]
mylist <- list_of_restable[1][1]
mylist <- list_of_restable[1]
mylist <-mylist[1]
mylist <-mylist[[1]]
b<-mylist[[1]]
c <- list_of_restable[[1]]
c <- list_of_restable[1]
mylist <- c
cc<-mylist [[1]]
c <- list_of_restable[1]
mylist <- c[1]
cc<-mylist [[1]]
c <- list_of_restable[1]
mylist <- c[[1]]
cc <- unlist(list_of_restable, recursive=FALSE)
mylist <- cc[1]
ccc<-mylist [[1]]
list_of_restable <-list(readRDS("results/India_potfolio_day_1.RDS"),readRDS("results/India_potfolio_day_2.RDS"))  # читаем из файла что там есть
list_of_restable <- unlist(list_of_restable, recursive=FALSE)
knit(input="2html_5days_short.rmd", output="2html_5days_short.md", encoding='UTF-8')
markdownToHTML("2html_5days_short.md","results/Календарные_эффекты.html", stylesheet="view/custom.css")
source(markdown)
library(markdown)
markdownToHTML("2html_5days_short.md","results/Календарные_эффекты.html", stylesheet="view/custom.css")
file.remove("2html_5days_short.md")
knit(input="2html_5days_short.rmd", output="2html_5days_short.md", encoding='UTF-8')
file.remove("2html_5days_short.md")
knit(input="2html_5days_short.rmd", output="2html_5days_short.md", encoding='UTF-8')
#markdownToHTML("2html_5days_short.md","results/Календарные_эффекты_.html", stylesheet="view/custom.css")
markdownToHTML("2html_5days_short.md","results/Календарные_эффекты(2 дня).html")
knit(input="2html_5days_short.rmd", output="2html_5days_short.md", encoding='UTF-8')
#markdownToHTML("2html_5days_short.md","results/Календарные_эффекты_.html", stylesheet="view/custom.css")
markdownToHTML("2html_5days_short.md","results/Календарные_эффекты(2 дня).html")
country_name <- "Индия"
country_name_eng <- "India"
#
setwd("/home/nazarov/02-fmlab.hse.ru/02 - независимость от дня недели/")
